# Autonomous WhatsApp AI Agent Using LangGraph

  
A multimodal whatsapp assistant powered by a LangGraph agentic workflow. This project integrates persistent conversational memory via PostgreSQL, real-time messaging via FastAPI, Retrieval-Augmented Generation (RAG) for querying complex documents, and native multimodal processing for voice notes and images.
  
## System Architecture

  This bot handles natural, multi-turn conversations while autonomously deciding when to search vector databases for external context, transcribe audio voice notes, or analyze incoming images.
  
### Model & Tech Stack

* **Text & Reasoning Engine:** OpenAI GPT-OSS-20b (Hosted on Groq)

* **Vision & Image Understanding:** Meta llama-4-scout-17b-16e-instruct (Hosted on Groq)

* **Audio Transcription:** Whisper-large-v3-turbo (Hosted on Groq)

* **Orchestration:** LangChain & LangGraph (State-machine agent routing)

* **Backend Framework:** FastAPI & Uvicorn (Asynchronous webhook handling)

* **Vector Database:** Pinecone (Document embeddings and semantic RAG search)

* **Memory / SQL Database:** Supabase PostgreSQL (Persistent checkpointing for LangGraph)

* **Messaging API:** Whapi.cloud (WhatsApp Cloud API gateway)

## Key Features

* **Agentic Routing:** Utilizes a state-graph architecture to route queries, manage tool-calling, and maintain dynamic conversation states.

* **Multimodal Vision:** Integrates Meta llama-4-scout-17b-16e-instruct to seamlessly process and analyze images sent directly through the WhatsApp chat.

* **Voice Note Processing:** Uses the Whisper-large-v3-turbo to instantly transcribe incoming WhatsApp audio messages into text before feeding them to the agent.

* **Persistent Memory:** Connects directly to Supabase to serialize and store message objects, giving the agent long-term context across multiple sessions.

* **Vector RAG Pipeline:** Integrated with Pinecone and LangChain's `PyPDFLoader` to retrieve semantic context from uploaded technical materials.

## Project Structure

* `app.py` - The FastAPI server, Whapi webhook handler, llama-4-scout image understanding, and Whisper audio transcription logic.

* `agent.py` - The LangGraph state graph, tools binding, and LLM initialization.

* `vector_store.py` - Pinecone database connection and PDF ingestion pipeline.

* `requirements.txt` - Version-locked dependencies for secure deployment.

  
## Local Setup & Installation

### 1. Prerequisites (API Keys)

To run this project, you will need free accounts and API keys from the following services:

* **Whapi:** Go to [Whapi.cloud](https://whapi.cloud/), scan the QR code with your WhatsApp app to link a number, and copy the API token from your dashboard.

* **Groq:** Get a free API key from the [Groq Console](https://console.groq.com/). This single key powers the text, vision, and transcription models.

* **Supabase:** Create a new PostgreSQL database on [Supabase](https://supabase.com/) and copy the connection pooling string.

* **Pinecone:** Create a free serverless index on [Pinecone](https://www.pinecone.io/) and copy the API key.

### 2. Clone the repository

```bash

git clone [https://github.com/yourusername/whatsapp-langgraph-agent.git](https://github.com/yourusername/whatsapp-langgraph-agent.git)

cd whatsapp-langgraph-agent

```

### 3. Install Dependencies

```bash

pip install -r requirements.txt

```

### 4. Setup Environment Variables

Create a .env file in the root directory and add the credentials:

```Plaintext

WHAPI_TOKEN=your_whapi_token

SUPABASE_DB_URL=your_supabase_db_url

PINECONE_API_KEY=your_pinecone_key

GROQ_API_KEY=your_groq_key

```

### 5. Run the Local Backend Server

```bash

uvicorn app:app --host 0.0.0.0 --port 8000

```

### 6. Expose the Server to the Internet

To send messages using Whapi Whatsapp API you need to expose port 8000 using a secure tunnel

```bash

ngrok http 8000

```

Copy the Forwarding URL generated by ngrok. Then go to Whapi dashboard, navigate to webhooks and past the ngrok URL with /webhook (e.g. https://1234-abcd.ngrok-free.app/webhook).
